{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeSOQmzZcDTHmFfZRwzy7G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariiaKalinina/R/blob/main/func_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTs7UQQ-Z0eX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from math import *\n",
        "from scipy.stats import pearsonr\n",
        "from scipy import integrate\n",
        "from numpy import linalg as LA\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from numba import njit\n",
        "import numpy as np\n",
        "from scipy.integrate import dblquad\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.colors\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as font_manager\n",
        "%matplotlib inline\n",
        "csfont = {'fontname':'Times New Roman'}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Your imports\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, QuantileTransformer, FunctionTransformer, MinMaxScaler\n",
        "from sklearn.random_projection import GaussianRandomProjection\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
        "\n",
        "import time\n",
        "import math\n",
        "from sklearn.metrics import roc_curve, average_precision_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "lOgwQF2Yx8Vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
      ],
      "metadata": {
        "id": "rRNMw0k99f9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "\n",
        "  # Assuming X_train, y_train, X_val, y_val, X_test, y_test are defined\n",
        "\n",
        "  RMSE_validation, RMSE_test, RMSE_train = [], [], []\n",
        "  R2_validation, R2_test, R2_train = [], [], []\n",
        "  MAE_validation, MAE_test, MAE_train = [], [], []\n",
        "  model_name = []\n",
        "\n",
        "  # List of models to evaluate\n",
        "  models_list = [\n",
        "      RandomForestRegressor(random_state=0xC0FFEE),\n",
        "      ExtraTreesRegressor(random_state=0xC0FFEE),\n",
        "      xgb.XGBRegressor(random_state=0xC0FFEE),\n",
        "      LinearRegression(),\n",
        "      Ridge(),\n",
        "      KNeighborsRegressor(),\n",
        "      DecisionTreeRegressor(),\n",
        "      GradientBoostingRegressor(random_state=0xC0FFEE),  # Added Gradient Boosting\n",
        "      CatBoostRegressor(silent=True, random_state=0xC0FFEE),  # Added CatBoost\n",
        "  ]\n",
        "\n",
        "  # Parameter grids for each model\n",
        "  p_g1 = {\n",
        "      'n_estimators': np.arange(2, 200, 20),\n",
        "      'min_samples_split': np.arange(2, 20, 2)\n",
        "  }\n",
        "\n",
        "  p_g2 = p_g1  # Same as p_g1 for simplicity\n",
        "\n",
        "  p_g3 = {\n",
        "      'n_estimators': np.arange(2, 200, 20),\n",
        "      \"learning_rate\": np.linspace(0.005, 1, 10)\n",
        "  }\n",
        "\n",
        "  p_g4 = {  # Linear Regression has no hyperparameters to tune\n",
        "  }\n",
        "\n",
        "  p_g5 = {  # Ridge Regression parameters\n",
        "      'alpha': np.logspace(-3, 3, 7),  # Regularization strength\n",
        "  }\n",
        "\n",
        "  p_g6 = {  # KNeighbors Regressor parameters\n",
        "      'n_neighbors': np.arange(1, 21),   # Number of neighbors\n",
        "      'weights': ['uniform', 'distance'], # Weight function used in prediction\n",
        "  }\n",
        "\n",
        "  p_g7 = {  # Decision Tree Regressor parameters\n",
        "      'max_depth': [None] + list(np.arange(1, 11)),   # Maximum depth of the tree\n",
        "      'min_samples_split': np.arange(2, 21),           # Minimum number of samples required to split an internal node\n",
        "  }\n",
        "\n",
        "  p_g8 = {  # Gradient Boosting parameters\n",
        "      'n_estimators': np.arange(50, 301, 50),          # Number of boosting stages to be run\n",
        "      'learning_rate': [0.01, 0.1, 0.2, 0.5],                # Step size shrinkage used in update to prevents overfitting\n",
        "      'max_depth': np.arange(2, 12, 2),                           # Maximum depth of the individual regression estimators\n",
        "  }\n",
        "\n",
        "  p_g9 = {  # CatBoost parameters (basic)\n",
        "      'iterations': [50, 100, 150, 200],              # Number of boosting iterations\n",
        "      'learning_rate': np.logspace(-3, 0, 5),                     # Learning rate for boosting steps\n",
        "      'depth': np.arange(2, 12, 2),                                  # Depth of the tree\n",
        "  }\n",
        "\n",
        "  params_list = [p_g1, p_g2, p_g3, p_g4, p_g5, p_g6, p_g7, p_g8, p_g9]\n",
        "\n",
        "  # Model training and evaluation loop\n",
        "  for reg, grid in zip(models_list, params_list):\n",
        "      model_name.append(type(reg).__name__)\n",
        "      gs = GridSearchCV(reg, param_grid=grid, n_jobs=-1, cv=5,\n",
        "                        scoring='neg_mean_squared_error')\n",
        "\n",
        "      gs.fit(X_train, y_train)\n",
        "\n",
        "      best_reg = reg.__class__(**gs.best_params_)\n",
        "\n",
        "      print(f'{type(reg).__name__}: Best Params: {gs.best_params_}')\n",
        "\n",
        "      # Evaluate using cross-validation on the training set\n",
        "      cv_results = gs.cv_results_\n",
        "      best_score = np.min(cv_results['mean_test_score'])\n",
        "\n",
        "      print(f'Cross-validated MSE: {-best_score:.2f}')\n",
        "\n",
        "      best_reg.fit(X_train, y_train)\n",
        "\n",
        "      y_pred_val = best_reg.predict(X_val)\n",
        "      y_pred_train = best_reg.predict(X_train)\n",
        "      y_pred_test = best_reg.predict(X_test)\n",
        "\n",
        "      # Validation metrics\n",
        "      print('Validation MSE:', round(mean_squared_error(y_pred_val, y_val), 2))\n",
        "      print('Validation R^2:', round(r2_score(y_val, y_pred_val), 2))\n",
        "      print('Validation MAE:', round(mean_absolute_error(y_val, y_pred_val), 2))\n",
        "\n",
        "      RMSE_validation.append(round(mean_squared_error(y_pred_val, y_val), 2))\n",
        "      R2_validation.append(round(r2_score(y_val, y_pred_val), 2))\n",
        "      MAE_validation.append(round(mean_absolute_error(y_val, y_pred_val), 2))\n",
        "\n",
        "      # Training metrics\n",
        "      print('Train MSE:', round(mean_squared_error(y_pred_train, y_train), 2))\n",
        "      print('Train R^2:', round(r2_score(y_train, y_pred_train), 2))\n",
        "      print('Train MAE:', round(mean_absolute_error(y_train, y_pred_train), 2))\n",
        "\n",
        "      RMSE_train.append(round(mean_squared_error(y_pred_train, y_train), 2))\n",
        "      R2_train.append(round(r2_score(y_train, y_pred_train), 2))\n",
        "      MAE_train.append(round(mean_absolute_error(y_train, y_pred_train), 2))\n",
        "\n",
        "      # Test metrics\n",
        "      print('Test MSE:', round(mean_squared_error(y_pred_test, y_test), 2))\n",
        "      print('Test R^2:', round(r2_score(y_test, y_pred_test), 2))\n",
        "\n",
        "      RMSE_test.append(round(mean_squared_error(y_pred_test, y_test), 2))\n",
        "      R2_test.append(round(r2_score(y_test, y_pred_test), 2))\n",
        "      MAE_test.append(round(mean_absolute_error(y_test, y_pred_test), 2))\n",
        "\n",
        "      print(' ')"
      ],
      "metadata": {
        "id": "7VjeXCwN9Wfr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}